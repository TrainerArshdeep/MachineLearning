{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277c896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e555d386",
   "metadata": {},
   "source": [
    "The mnist.load_data() method returns us the training data, its labels and also the testing data and its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e4f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6dbdeeb",
   "metadata": {},
   "source": [
    "The dimension of the training data is (60000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bb4608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f363a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24ce3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6b98e5a",
   "metadata": {},
   "source": [
    "A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf17508",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 25\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8047cd5c",
   "metadata": {},
   "source": [
    "The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5f073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6e1ef5a",
   "metadata": {},
   "source": [
    "We will then compile the model with the Adadelta optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce87dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52619040",
   "metadata": {},
   "source": [
    "The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a998c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "469/469 [==============================] - 88s 186ms/step - loss: 26.7939 - accuracy: 0.1979 - val_loss: 3.0927 - val_accuracy: 0.6227\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 12.6950 - accuracy: 0.3672 - val_loss: 1.7507 - val_accuracy: 0.7521\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 7.5090 - accuracy: 0.4685 - val_loss: 1.1554 - val_accuracy: 0.7953\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 5.0476 - accuracy: 0.5273 - val_loss: 0.8226 - val_accuracy: 0.8125\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 88s 188ms/step - loss: 3.6890 - accuracy: 0.5596 - val_loss: 0.6538 - val_accuracy: 0.8173\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 89s 189ms/step - loss: 2.8384 - accuracy: 0.5755 - val_loss: 0.6163 - val_accuracy: 0.8139\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 2.3473 - accuracy: 0.5803 - val_loss: 0.6671 - val_accuracy: 0.8024\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 1.9828 - accuracy: 0.5796 - val_loss: 0.7389 - val_accuracy: 0.7925\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 1.7381 - accuracy: 0.5894 - val_loss: 0.7900 - val_accuracy: 0.7914\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 1.6144 - accuracy: 0.5941 - val_loss: 0.8203 - val_accuracy: 0.7914\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 1.4960 - accuracy: 0.6039 - val_loss: 0.8196 - val_accuracy: 0.7958\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 1.3846 - accuracy: 0.6166 - val_loss: 0.7901 - val_accuracy: 0.8100\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 87s 186ms/step - loss: 1.3352 - accuracy: 0.6293 - val_loss: 0.7579 - val_accuracy: 0.8203\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 1.2711 - accuracy: 0.6438 - val_loss: 0.7293 - val_accuracy: 0.8287\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 1.2204 - accuracy: 0.6556 - val_loss: 0.6930 - val_accuracy: 0.8366\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 1.1640 - accuracy: 0.6685 - val_loss: 0.6534 - val_accuracy: 0.8464\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 60s 129ms/step - loss: 1.1232 - accuracy: 0.6794 - val_loss: 0.6201 - val_accuracy: 0.8537\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 1.0837 - accuracy: 0.6906 - val_loss: 0.5879 - val_accuracy: 0.8609\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 1.0651 - accuracy: 0.6981 - val_loss: 0.5587 - val_accuracy: 0.8694\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 1.0252 - accuracy: 0.7053 - val_loss: 0.5332 - val_accuracy: 0.8734\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 1.0045 - accuracy: 0.7140 - val_loss: 0.5084 - val_accuracy: 0.8793\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.9696 - accuracy: 0.7218 - val_loss: 0.4905 - val_accuracy: 0.8811\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.9511 - accuracy: 0.7286 - val_loss: 0.4739 - val_accuracy: 0.8844\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.9173 - accuracy: 0.7367 - val_loss: 0.4573 - val_accuracy: 0.8886\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 73s 157ms/step - loss: 0.9028 - accuracy: 0.7445 - val_loss: 0.4407 - val_accuracy: 0.8939\n",
      "The model has successfully trained\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,\n",
    "                 verbose=1,validation_data=(x_test, y_test))\n",
    "print(\"The model has successfully trained\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7de82d39",
   "metadata": {},
   "source": [
    "After training, we save the weights and model definition in the ‘mnist.h5’ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c430be63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist.h5')\n",
    "print(\"Saving the model as mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cdd7b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4407407343387604\n",
      "Test accuracy: 0.8938999772071838\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "397a9ae0",
   "metadata": {},
   "source": [
    "We create a canvas where we can draw by capturing the mouse event and with a button, we trigger the predict_digit() function and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebf524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('mnist.h5')\n",
    "\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "\n",
    "        self.x = self.y = 0\n",
    "\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
